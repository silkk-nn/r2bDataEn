{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Start] Workshop2 - Data Cleansing with Spark",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silkk-nn/r2bDataEn/blob/main/%5BStart%5D_Workshop2_Data_Cleansing_with_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SQc75fHqX85"
      },
      "source": [
        "# Workshop 2: Data Cleansing with Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnxzvnOmsN-X"
      },
      "source": [
        "ภาพรวมของคอร์สนี้\n",
        "\n",
        "![alt text](https://cdn-std.droplr.net/files/acc_513973/z7Gqhs)\n",
        "\n",
        "Workshop 2 นี้เราจะทำอะไรกันบ้าง\n",
        "\n",
        "![alt text](https://cdn-std.droplr.net/files/acc_513973/SCN8wh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-V1EYBzrt5b"
      },
      "source": [
        "## Spark Cheatsheet by DataCamp\n",
        "\n",
        "แนะนำให้โหลดเก็บไว้ อุ่นใจกว่า <3\n",
        "\n",
        "![alt text](https://cdn-std.droplr.net/files/acc_513973/PglivG)\n",
        "\n",
        "**RDD:**\n",
        "https://www.datacamp.com/community/blog/pyspark-cheat-sheet-python \n",
        "\n",
        "**DataFrame:**\n",
        "https://www.datacamp.com/community/blog/pyspark-sql-cheat-sheet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGaAOQ3Yi7PC"
      },
      "source": [
        "## ข้อมูลขายของออนไลน์\n",
        "### Data Dictionary\n",
        "https://archive.ics.uci.edu/ml/datasets/Online+Retail\n",
        "\n",
        "This is a transactional data set which contains all the transactions occurring between 01/12/2018 and 09/12/2019 for a UK-based and registered non-store online retail.\n",
        "\n",
        "The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
        "\n",
        "- InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "- StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "- Description: Product (item) name. Nominal.\n",
        "- Quantity: The quantities of each product (item) per transaction. Numeric.\n",
        "- InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "- UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n",
        "- CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "- Country: Country name. Nominal, the name of the country where each customer resides.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ06tCiTn7z9"
      },
      "source": [
        "## ลง Pyspark และเชื่อมต่อ Google Colab กับ Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Qym1H89mfB"
      },
      "source": [
        "# ลง Spark ใน Google Colab\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xzvf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark==1.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dwpn8wv9lgO"
      },
      "source": [
        "# Set enviroment variable ให้รู้จัก Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHNIVIS8ygwc"
      },
      "source": [
        "# ลง pyspark ผ่านคำสั่ง pip\n",
        "!pip install pyspark==2.4.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aX_fiEkrkVo"
      },
      "source": [
        "#### ใช้งาน Spark\n",
        "\n",
        "ใช้ `local[*]` เพื่อเปิดการใช้งานการประมวลผลแบบ multi-core. Spark จะใช้ CPU ทุก core ที่อนุญาตให้ใช้งานในเครื่อง."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASZqLPXDPJJB"
      },
      "source": [
        "# Server ของ Google Colab มีกี่ Core\n",
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6-PYi44nH2e"
      },
      "source": [
        "# สร้าง Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Fuuh_8ocdw"
      },
      "source": [
        "# Get Python version\n",
        "import sys\n",
        "sys.version_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obpcIPP4oOvk"
      },
      "source": [
        "# Get Spark version\n",
        "spark.version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzy7awN1orhZ"
      },
      "source": [
        "#### เชื่อมต่อ Google Drive\n",
        "\n",
        "เมื่อรันแล้วจะมีลิงค์ให้กด กรุณากดลิงค์ และเลือกบัญชี Google ของคุณ จากนั้นก็อปปี้โค้ดมาใส่ในกล่องข้อความ (หรือดูวิธีตามวีดิโอ Workshop ก็ได้ครับ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWqYG_VcoeGF"
      },
      "source": [
        "# เชื่อมต่อ Google colab กับ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pn2zW6xqrtY"
      },
      "source": [
        "## Load data\n",
        "\n",
        "แก้ลิงค์ไฟล์ให้เป็นลิงค์ใน Google Drive ของคุณเอง มิฉะนั้นจะรันแล้ว Error (ดูวิธีได้จากในวีดิโอ Workshop)\n",
        "\n",
        "ใช้คำสั่ง `spark.read.csv` เพื่ออ่านข้อมูลจากไฟล์ CSV\n",
        "\n",
        "Arguments:\n",
        "\n",
        "Header = True << บอกให้ Spark รู้ว่าบรรทัดแรกในไฟล์ CSV เป็น Header\n",
        "\n",
        "\n",
        "Inferschema = True << บอกให้ Spark พยายามเดาว่าแต่ละ column มี type เป็นอะไร ถ้าตั้งเป็น False, ทุก column จะถูกอ่านเป็น string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ho4MvryoY9u"
      },
      "source": [
        "dt = spark.read.csv('/content/drive/My Drive/Data Science Chill/Online 2020: Road to Data Engineer/Workshop Files/WS2/Data Files/Online Retail WS2.csv', header = True, inferSchema = True, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKBjHvpzTM6-"
      },
      "source": [
        "### Data Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruTiAh69nkWT"
      },
      "source": [
        "Data Profiling is a process of analysing summary of the data.\n",
        "\n",
        "Example: max, min, average, sum, how many missing values etc.\n",
        "\n",
        "#### Data\n",
        "\n",
        "> Columns\n",
        "- InvoiceNo\n",
        "- StockCode\n",
        "- Description\n",
        "- Quantity\n",
        "- InvoiceDate\n",
        "- UnitPrice\n",
        "- CustomerID\n",
        "- Country"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpb7PcpSrOWe"
      },
      "source": [
        "dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rEzUAWCS3Gd"
      },
      "source": [
        "dt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOgygtSZUenr"
      },
      "source": [
        "dt.show(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hfU4p2sCuef"
      },
      "source": [
        "# Show Schema\n",
        "dt.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er9ltLyoCJxo"
      },
      "source": [
        "# Show Schema (อีกแบบ)\n",
        "dt.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brQdwlRpCVSi"
      },
      "source": [
        "# นับจำนวนแถวและ column\n",
        "print((dt.count(), len(dt.columns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ9V4iQKUi2i"
      },
      "source": [
        "# สรุปข้อมูลสถิติ\n",
        "dt.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ7xtdKgVvKO"
      },
      "source": [
        "# สรุปข้อมูลสถิติ\n",
        "dt.summary().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBmjzCqjM_MR"
      },
      "source": [
        "# สรุปข้อมูลสถิติเฉพาะ column ที่ระบุ\n",
        "dt.select(\"Quantity\", \"UnitPrice\").describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXLwFlXdWNmI"
      },
      "source": [
        "### Exercise: ลองเช็ค Median ของ ค่า Quantity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9h9CY1XWKf3"
      },
      "source": [
        "# Write Answer here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7gUknDUB8Wj"
      },
      "source": [
        "### ดู Summary แล้วเห็นอะไรบ้าง?\n",
        "- Missing values?\n",
        "- Mean, Min, Max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe1VrTpETgar"
      },
      "source": [
        "## EDA - Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRmig4MaQm2s"
      },
      "source": [
        "### Non-Graphical EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGkcJ3kDQmJ5"
      },
      "source": [
        "# Select text-based information\n",
        "dt.where(dt['Quantity'] < 0).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOnfZz27XhjX"
      },
      "source": [
        "### Exercise: \n",
        "1. ลองเลือก Quantity ระหว่าง 50 - 120\n",
        "2. ลองเลือก UnitPrice ระหว่าง 0.1 - 0.5\n",
        "3. Quantity ระหว่าง 50 - 120 และ UnitPrice ระหว่าง 0.1 - 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2-Ot31WX2uc"
      },
      "source": [
        "# TODO: 1. Quantity 50 - 120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWZ8SRUOX2qJ"
      },
      "source": [
        "# TODO: 2. UnitPrice 0.1 - 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgPm8dsraxNx"
      },
      "source": [
        "# TODO: 3. Quantity 50 - 120 and UnitPrice 0.1 - 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN3m9gpHkS5H"
      },
      "source": [
        "### Graphical EDA\n",
        "\n",
        "\n",
        "Spark ไม่ได้ถูกพัฒนามาเพื่องาน plot ข้อมูล เพราะฉะนั้นเราจะใช้ package `seaborn` `matplotlib` และ `pandas` ในการ plot ข้อมูลแทน"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWu_zxdONk0o"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "861ui21dNy-N"
      },
      "source": [
        "# แปลง Spark Dataframe เป็น Pandas Dataframe\n",
        "dt_pd = dt.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpF73lu_Rn-_"
      },
      "source": [
        "dt_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcU3qZB2RjUp"
      },
      "source": [
        "# เลือกข้อมูล 500 แถวแรกเพื่อความรวดเร็วและความเรียบง่ายในการ visualize ข้อมูล\n",
        "dt_pd_subset = dt_pd[0:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBv0DP4YOAQF"
      },
      "source": [
        "# Boxplot\n",
        "sns.boxplot(dt_pd_subset['UnitPrice'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYbSz2HuO2sr"
      },
      "source": [
        "# Histogram\n",
        "sns.distplot(dt_pd_subset['UnitPrice']) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1N-03d9O83E"
      },
      "source": [
        "# Scatterplot\n",
        "dt_pd_subset.plot.scatter('UnitPrice', 'Quantity')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVliQZLC0LuP"
      },
      "source": [
        "#### Bonus: สร้าง interactive chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bb0F-9zTI1X"
      },
      "source": [
        "# Plotly - interactive chart\n",
        "import plotly.express as px\n",
        "fig = px.scatter(dt_pd_subset, 'UnitPrice', 'Quantity')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXLHVsbwk08q"
      },
      "source": [
        "### Type Conversion\n",
        "\n",
        "แปลง `InvoiceDate` จาก string -> date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb7BB-e3k4g-"
      },
      "source": [
        "# Show top 5 rows\n",
        "dt.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7gFtSr0Fbne"
      },
      "source": [
        "# Show Schema\n",
        "dt.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNVwy-FkHDrT"
      },
      "source": [
        "Is the date DD/MM/YYYY or MM/DD/YYYY? Let's find out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu6po7nVGhj6"
      },
      "source": [
        "# Show unique Invoice Date\n",
        "dt.select(\"InvoiceDate\").distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnerFBErFelC"
      },
      "source": [
        "# แปลง string เป็น date\n",
        "from pyspark.sql import functions as f\n",
        "\n",
        "# dt_temp = dt.withColumn('InvoiceDateTime', functions.to_date(\n",
        "#     functions.unix_timestamp('InvoiceDate', 'dd/MM/yyyy HH:mm').cast('timestamp')\n",
        "# ))\n",
        "\n",
        "dt_temp = dt.withColumn('InvoiceDateTime', \n",
        "    f.unix_timestamp('InvoiceDate', 'dd/MM/yyyy HH:mm').cast('timestamp')\n",
        ")\n",
        "dt_temp.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq7sQ-h6T6cp"
      },
      "source": [
        "dt_temp.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrntLk52LN1Q"
      },
      "source": [
        "dt_final = dt_temp.drop('InvoiceDate')\n",
        "dt_final.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRYXS2J7Mo5M"
      },
      "source": [
        "dt_final.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNWeSFR0TqHt"
      },
      "source": [
        "## Data Cleansing with Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlewC3HjbMty"
      },
      "source": [
        "### Anomalies Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQmzIi6c2Ugp"
      },
      "source": [
        "#### Syntactical Anomalies\n",
        "**Lexical errors** เช่น พิมพ์ผิด"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htfmeHuZ2VPo"
      },
      "source": [
        "# Check country distinct values. Find something interesting?\n",
        "# ลองมาดูชื่อประเทศกัน เจออะไรบ้าง ?\n",
        "dt_final.select(\"Country\").distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSGUoi-eUl5U"
      },
      "source": [
        "dt_final.where(dt_final['Country'] == 'EIREs').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03YDBKivjIfh"
      },
      "source": [
        "# เปลี่ยน EIREs เป็น EIRE\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "dt_temp_eire = dt_final.withColumn(\"CountryUpdate\", when(dt_final['Country'] == 'EIREs', 'EIRE').otherwise(dt_final['Country']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHp2xBfIknNx"
      },
      "source": [
        "# Check the result\n",
        "dt_temp_eire.select(\"CountryUpdate\").distinct().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXspKbmMlDEA"
      },
      "source": [
        "# Create final Dataframe\n",
        "dt_final_eire = dt_temp_eire.drop(\"Country\").withColumnRenamed('CountryUpdate', 'Country')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jakWvW6EVdcv"
      },
      "source": [
        "dt_final_eire.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kyrqLYF2YjO"
      },
      "source": [
        "#### Semantic Anomalies\n",
        "\n",
        "**Integrity constraints**: ค่าอยู่นอกเหนือขอบเขตของค่าที่รับได้ เช่น\n",
        "- Stockcode: ค่าจะต้องเป็นตัวเลข 5 ตัว"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iasmydx2TEYG"
      },
      "source": [
        "dt_final_eire.select(\"Stockcode\").show(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVtj_wvpsdn4"
      },
      "source": [
        "dt_final_eire.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3H6sWVsrSn-"
      },
      "source": [
        "dt_final_eire.filter(dt_final_eire[\"Stockcode\"].rlike(\"^[0-9]{5}$\")).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnUrouqasixk"
      },
      "source": [
        "# ลองดูข้อมูลที่ถูกต้อง\n",
        "dt_final_eire.filter(dt_final_eire[\"Stockcode\"].rlike(\"^[0-9]{5}$\")).show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tE-VcSQXWzp"
      },
      "source": [
        "# ลองดูข้อมูลที่ไม่ถูกต้อง\n",
        "dt_correct_stockcode = dt_final_eire.filter(dt_final_eire[\"Stockcode\"].rlike(\"^[0-9]{5}$\"))\n",
        "dt_incorrect_stockcode = dt_final_eire.subtract(dt_correct_stockcode)\n",
        "\n",
        "dt_incorrect_stockcode.show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38ekkpo7XyDG"
      },
      "source": [
        "> คุณเห็น Pattern ของ Stock Code ที่ไม่ถูกต้องหรือยัง?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2SAQYLuuKgX"
      },
      "source": [
        "# ลบตัวอักษรตัวสุดท้ายออกจาก stock code\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "dt_temp_stockcode = dt_final_eire.withColumn(\"StockcodeUpdate\", regexp_replace(dt_final_eire['Stockcode'], r'[A-Z]', ''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ko7m6mbwJJj"
      },
      "source": [
        "# Check the result\n",
        "dt_temp_stockcode.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6LoL8etxNSO"
      },
      "source": [
        "# Create final Dataframe\n",
        "dt_final_stockcode = dt_temp_stockcode.drop(\"Stockcode\").withColumnRenamed('StockcodeUpdate', 'StockCode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIcBie-jcAaC"
      },
      "source": [
        "dt_final_stockcode.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kCf3LsX2b8L"
      },
      "source": [
        "#### Missing values\n",
        "\n",
        "การเช็คและแก้ไข Missing Values (หากจำเป็น)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T11c7iUs24Cu"
      },
      "source": [
        "# Check จำนวน missing values ในแต่ละ column\n",
        "from pyspark.sql.functions import col,sum\n",
        "\n",
        "dt_final_stockcode.select(*[sum(col(c).isNull().cast(\"int\")).alias(c) for c in dt_final_stockcode.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUSOqJ4p0E2W"
      },
      "source": [
        "# Check ว่ามีแถวไหนที่ description เป็น null บ้าง\n",
        "\n",
        "dt_final_stockcode.where( dt_final_stockcode['Description'].isNull() ).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bi3ql4PzXae"
      },
      "source": [
        "# Check ว่ามีแถวไหนที่ customerID เป็น null บ้าง\n",
        "\n",
        "dt_final_stockcode.where( dt_final_stockcode['customerID'].isNull() ).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp3uwpf-Ty8Y"
      },
      "source": [
        "### Exercise:\n",
        "ทางทีม Data Analyst แจ้งว่าอยากให้เราแทน Customer ID ที่เป็น NULL ด้วย -1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnwxPdTHTyS5"
      },
      "source": [
        "# Write code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5DtVcoRUsFp"
      },
      "source": [
        "### Clean ข้อมูลด้วย Spark SQL\n",
        "\n",
        "![alt text](https://cdn-std.droplr.net/files/acc_513973/881iHw)\n",
        "\n",
        "เลือกเฉพาะข้อมูลที่ `unitPrice` กับ `Quantity` ถูกต้อง (มากกว่า 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMwaNBsSuygq"
      },
      "source": [
        "dt_final_stockcode.createOrReplaceTempView(\"sales\")\n",
        "dt_sql = spark.sql(\"SELECT * FROM sales\")\n",
        "dt_sql.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQLzG7jz06vU"
      },
      "source": [
        "dt_sql_count = spark.sql(\"SELECT count(*) as cnt_row FROM sales\")\n",
        "dt_sql_count.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFnsr05vYnOi"
      },
      "source": [
        "dt_sql_count = spark.sql(\"SELECT count(*) as cnt_row, country FROM sales GROUP BY Country ORDER BY cnt_row DESC\")\n",
        "dt_sql_count.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4coCNUH07yW"
      },
      "source": [
        "dt_sql_valid_price = spark.sql(\"SELECT count(*) as cnt_row FROM sales WHERE UnitPrice > 0 AND Quantity > 0\")\n",
        "dt_sql_valid_price.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hETimL9n1OxF"
      },
      "source": [
        "dt_sql_valid_price = spark.sql(\"SELECT * FROM sales WHERE UnitPrice > 0 AND Quantity > 0\")\n",
        "dt_sql_valid_price.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv0YK6cFgSiB"
      },
      "source": [
        "### Exercise: \n",
        "1. ลองเลือก Country USA ที่มี InvoiceDateTime ตังแต่วันที่ 2010-12-01 เป็นต้นไป และ UnitPrice เกิน 3.5 \n",
        "2. ลองเลือก Country France ที่มี InvoiceDateTime ตังแต่วันที่ 2010-12-05 เป็นต้นไป และ UnitPrice เกิน 5.5 และ Description มีคำว่า Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QHlrKnPgMRh"
      },
      "source": [
        "# TODO: Country USA ที่มี InvoiceDateTime ตั้งแต่วันที่ 2010-12-01 เป็นต้นไป และ UnitPrice เกิน 3.5\n",
        "dt_sql_usa = spark.sql(\"\"\"\n",
        "SELECT * FROM sales\n",
        "  WHERE InvoiceDateTime >= '2010-12-01'\n",
        "  AND UnitPrice > 3.5\n",
        "  AND Country='USA'\n",
        "\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgCm2SiKgMP7"
      },
      "source": [
        "# TODO: Country France ที่มี InvoiceDateTime ตังแต่วันที่ 2010-12-05 เป็นต้นไป และ UnitPrice เกิน 5.5 และ Description มีคำว่า Box\n",
        "dt_sql_france = spark.sql(\"\"\"\n",
        "SELECT * FROM sales\n",
        "  WHERE UnitPrice > 5.5\n",
        "  AND InvoiceDateTime >= '2010-12-05'\n",
        "  AND Country = 'France'\n",
        "  AND LOWER(Description) LIKE '%box%'\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu3WQ4g8UBra"
      },
      "source": [
        "## Save cleaned data เป็น CSV\n",
        "\n",
        "โดยปกติแล้ว Spark จะทำการ Save ออกมาเป็นหลายไฟล์ เพราะใช้หลายเครื่องในการประมวลผล"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6ZMEZ-8UIEJ"
      },
      "source": [
        "# Write as partitioned files (use multiple workers)\n",
        "dt_sql_valid_price.write.csv('Cleaned_Data_Now_Final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcPc7I-BYckx"
      },
      "source": [
        "เราสามารถบังคับให้ Spark ใช้เครื่องเดียวได้"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzMterYlWA5X"
      },
      "source": [
        "# Write as 1 file (use single worker)\n",
        "dt_sql_valid_price.coalesce(1).write.csv('Cleaned_Data_Now_Final_Single.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHJ93iwFY_rS"
      },
      "source": [
        "### Bonus Exercise: อ่านไฟล์ที่มีหลาย Part\n",
        "เช่น\n",
        "- /content/Cleaned_Data.csv/part-00000-25a1e27a-a2b1-4553-b8ae-e05a6c574b59-c000.csv\n",
        "- /content/Cleaned_Data.csv/part-00001-25a1e27a-a2b1-4553-b8ae-e05a6c574b59-c000.csv\n",
        "\n",
        "ป.ล. เครื่องคอมพิวเตอร์แต่ละท่านจะสร้างชื่อไฟล์ไม่เหมือนกัน กรุณาเช็คชื่อไฟล์ในแท็บ Files ด้านซ้าย (หรือดูวิธีการได้จากวีดิโอ Workshop)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_xj7NIbSv0w"
      },
      "source": [
        "# สำคัญ: แก้โค้ดด้านล่างนี้เป็นชื่อไฟล์ที่ Spark สร้างขึ้นมาใน Google Drive ของนะครับ เพราะชื่อไฟล์จะสุ่มสร้างออกมา ถ้ารันโดยไม่แก้เลยจะ Error\n",
        "# อ่าน CSV ไฟล์ที่ 1\n",
        "part1 = spark.read.csv('/content/Cleaned_Data_Now_Final.csv/part-00000-a156ec9a-ff0a-4baf-933e-3f7888196855-c000.csv', header = True, inferSchema = True, )\n",
        "part1.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_mj3koGS3Rn"
      },
      "source": [
        "# สำคัญ: แก้โค้ดด้านล่างนี้เป็นชื่อไฟล์ที่ Spark สร้างขึ้นมาใน Google Drive ของนะครับ เพราะชื่อไฟล์จะสุ่มสร้างออกมา ถ้ารันโดยไม่แก้เลยจะ Error\n",
        "# อ่าน CSV ไฟล์ที่ 2\n",
        "part2 = spark.read.csv('/content/Cleaned_Data_Now_Final.csv/part-00001-a156ec9a-ff0a-4baf-933e-3f7888196855-c000.csv', header = True, inferSchema = True, )\n",
        "part2.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJN1WjglaKK4"
      },
      "source": [
        "# วิธีอ่าน CSV ทุกไฟล์ในโฟลเดอร์นี้\n",
        "# Write Code Here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}